\documentclass{sig-alternate}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[T1,T2A]{fontenc}
\usepackage{lmodern}
\usepackage[activate=compatibility]{microtype}

% autoref command
\usepackage[hyphens]{url}
\usepackage[pdftex,urlcolor=black,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}

\usepackage{enumitem}

% todo macro
\usepackage{color}
\newcommand{\todo}[1]{\noindent\textcolor{red}{{\bf \{TODO}: #1{\bf \}}}}

% listings and Verbatim environment
\usepackage{fancyvrb}
\usepackage{relsize}
\usepackage{listings}
\usepackage{verbatim}
\newcommand{\defaultlistingsize}{\fontsize{7.5pt}{9.5pt}}
\newcommand{\inlinelistingsize}{\fontsize{8pt}{11pt}}
\newcommand{\smalllistingsize}{\fontsize{7.5pt}{9.5pt}}
\newcommand{\listingsize}{\defaultlistingsize}
\RecustomVerbatimCommand{\Verb}{Verb}{fontsize=\inlinelistingsize}
\RecustomVerbatimEnvironment{Verbatim}{Verbatim}{fontsize=\defaultlistingsize}
\lstset{frame=lines,captionpos=b,numberbychapter=false,escapechar=§,
        aboveskip=0.5em,belowskip=0em,abovecaptionskip=0em,belowcaptionskip=0em,
framexbottommargin=-1em,
        basicstyle=\ttfamily\listingsize\selectfont}

% use Courier from this point onward
\let\oldttdefault\ttdefault
\renewcommand{\ttdefault}{pcr}
\let\oldurl\url
\renewcommand{\url}[1]{\inlinelistingsize\oldurl{#1}}

\lstdefinelanguage{JavaScript}{
  keywords={push, typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break},
  keywordstyle=\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{darkgray},
  stringstyle=\color{red},
  morestring=[b]',
  morestring=[b]"
}

% linewrap symbol
\definecolor{grey}{RGB}{130,130,130}
\newcommand{\linewrap}{\raisebox{-.6ex}{\textcolor{grey}{$\hookleftarrow$}}}

% more pleasing quote environment
\usepackage{tikz}
\newcommand*{\openquote}{\tikz[remember picture,overlay,xshift=-7pt,yshift=1pt]
     \node (OQ) {\fontfamily{fxl}\fontsize{16}{16}\selectfont``};\kern0pt}
\newcommand*{\closequote}{\tikz[remember picture,overlay,xshift=2pt,yshift=-4.5pt]
     \node (CQ) {\fontfamily{fxl}\fontsize{16}{16}\selectfont''};}
\renewenvironment{quote}%
{\setlength{\parindent}{1cm}\par\openquote}
{\closequote\vspace{-4.5pt}
}

% bullet numbers
\usepackage{tkz-graph}
\usetikzlibrary{matrix,arrows,decorations.pathmorphing,shapes}
\newcommand{\dobulletnumber}[1]{\node[circle,text=white,fill=gray,anchor=west,inner sep=1pt] {\sffamily #1}}
\newcommand{\bulletnumber}[1]{\tikz[baseline=-2.5,overlay]\dobulletnumber{#1};}
\newcommand{\bulletref}[1]{\tikz[baseline=-2.5]\dobulletnumber{\fontsize{8}{8}\selectfont#1};}

\hyphenation{DBpedia RESTdesc}

%\def\baselinestretch{0.99}

\begin{document}

\title{MJ no more: using concurrent Wikipedia edit spikes with social network plausibility checks to detect breaking news}

\numberofauthors{1}\author{
\alignauthor
Thomas Steiner\\
	\affaddr{Google Germany GmbH}\\
	\affaddr{ABC-Str. 19}\\
	\affaddr{20354 Hamburg, Germany}\\
	\email{tomac@google.com}
}
\maketitle
\begin{abstract}
\fontencoding{T1}\selectfont
We have developed an application called Wikipedia Live Monitor
that monitors edits on different language versions of Wikipedia---%
as they happen in realtime.
Wikipedia articles in different languages are highly interlinked.
For example, the English article \emph{``en:2013\_Russian\_meteor\_event''}
on the topic of the February 15 meteoroid
that exploded over the region of Chelyabinsk Oblast, Russia,
is interlinked with \fontencoding{T2A}\selectfont
\emph{``ru:Падение\_метеорита\_на\_Урале\_в\_2013\_году''},
\fontencoding{T1}\selectfont \emph{i.e.},
the Russian article on the same topic.
As we monitor multiple language versions of Wikipedia in parallel,
we can exploit this fact to detect \emph{concurrent edit spikes}
of Wikipedia articles covering the same topics,
both in only one and in different languages.
We treat such concurrent edit spikes as signals
for potential breaking news events, whose plausibility we then check 
with full-text cross-language searches on multiple social networks.
Unlike the reverse approach of monitoring social networks first
and potentially checking plausibility on Wikipedia second,
the approach proposed in this paper has the advantage of
being less prone to false-positive alerts while being equally sensitive
to true-positive events, however, at a~fraction of the processing cost.

\end{abstract}

\category{H.3.3}{ Information Search and Retrieval}{Clustering}

\terms{Algorithms}

\keywords{breaking news detection, Wikipedia, social networks}

\section{Introduction}

\subsection{Motivation}

Shortly after the celebrity news website TMZ
broke the premature news that the King of Pop Michael Jackson~(MJ) had died,%
\footnote{\url{http://www.tmz.com/2009/06/25/michael-jackson-dies-death-dead-cardiac-arrest/},
accessed 02/18/2013}
the Internet slowed down.%
\footnote{\url{http://news.bbc.co.uk/2/hi/technology/8120324.stm}, accessed 02/18/2013}
Initially, Wikipedia's website administrators started noting abnormal load spikes~%
\cite{vibber2009currentevents} and shortly afterwards, caching issues
caused by a~so-called edit war~\cite{beaumont2009editwar} led the site to go down:
Wikipedia editors worldwide made concurrent edits
to the Michael Jackson Wikipedia article, doing and undoing changes
regarding the tense (present tense to past tense), death date,
and the circumstances of the at the time officially still unconfirmed fatality.
While the Wikipedia engineers have worked hard
to ensure that future edit wars or concurrent edits
do not take the site down again, there is without dispute a~lot of research potential
in analyzing such editing activity.

\subsection{Hypotheses and Research Questions}

In this paper, we present an application that monitors edits
of the different language versions of Wikipedia in realtime
in order to detect concurrent edit spikes that may be the source of
breaking news events.
When a~concurrent edit spike has been detected,
we use cross-language full-text searches on multiple social networks
as plausibility checks for filtering out false-positive alerts.
We are driven by the following hypotheses.

\begin{itemize}
  \item[(H1)] Breaking news events spread over social networks,
    independent from whether the news initially broke on a~social network or not.
  \item[(H2)] If a~breaking news event is important, it will be reflected on
    at least one language edition of Wikipedia.
  \item[(H3)] The time between when the news broke first and the news
    being reflected on Wikipedia is considerably short.   
\end{itemize}

These hypotheses lead us to the research questions below.

\begin{itemize}
  \item[(Q1)] Can concurrent Wikipedia edit spikes combined with
    social network plausibility checks capture major breaking news events,
    and with what delay?
  \item[(Q2)] Is the approach ``Wikipedia first, social networks second''
    at least as powerful as the reverse approach ``social networks first,
    Wikipedia second''?
\end{itemize}

\subsection{Paper Structure}
With this paper, we do not answer all research questions yet,
however, lay the foundation stone for future research in this area
by the introduction of the application Wikipedia Live Monitor.
The remainder of this paper is structured as follows.

\section{Related Work}

\cite{petrovic2010streamingfirststory}

\cite{osborne2012bieber}

\section{Implementation Details}

\subsection{Breaking News Criteria}

1) >= 5 Occurrences 
An article cluster must have at least n edits before it is considered a breaking news candidate.

2) <=60 Seconds Between Edits 
An article cluster may have at max n seconds in between edits in order to be regarded a breaking news candidate.

3) >=2 Concurrent Editors
An article cluster must be edited by at least n concurrent editors before it is considered a breaking news candidate.

4) <=240 Seconds Since Last Edit 
An article cluster is thrown out of the monitoring loop if its last edit is longer ago than n seconds.

\footnote{Raw IRC feeds of recent changes \url{http://meta.wikimedia.org/wiki/IRC/Channels\#Raw_feeds}, accessed 02/18/2013}
\footnote{Page view statistics for Wikimedia projects \url{http://dumps.wikimedia.org/other/pagecounts-raw/}, accessed 02/18/2013}

\section{Premature Evaluation}

\section{Conclusions and Future Work}

\bibliographystyle{abbrv}
\bibliography{www2013devtrack}

\balancecolumns
\end{document}